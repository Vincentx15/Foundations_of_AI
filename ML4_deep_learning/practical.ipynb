{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Practical Session 4 - Deep Learning with PyTorch\n",
    "In this session we will start with our toy task again.\n",
    "Remember how we solved it with an MLP in the first class ?\n",
    "We used scikit-learn, a one liner but without control over what was happening.\n",
    "\n",
    "We will start by implementing the model in Pytorch, in a basic way.\n",
    "\n",
    "Then we will work our way to making our code looks like a real Pytorch code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "np.random.seed(20)\n",
    "\n",
    "\n",
    "def base_function():\n",
    "    f = lambda x: 1.3 * x ** 3 - 3 * x ** 2 + 3.6 * x + 6.9\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "low, high = -1, 3\n",
    "n_points = 80\n",
    "\n",
    "# Get the values\n",
    "bfunc = base_function()\n",
    "xs = np.random.uniform(low, high, n_points)\n",
    "ys_noise = np.random.normal(size=len(xs))\n",
    "sample_ys = bfunc(xs)\n",
    "noisy_sample_ys = sample_ys + ys_noise\n",
    "\n",
    "# Plot the hidden function\n",
    "lsp = np.linspace(low, high)\n",
    "true_ys = bfunc(lsp)\n",
    "plt.plot(lsp, true_ys, linestyle='dashed')\n",
    "\n",
    "# Plot the samples\n",
    "plt.scatter(xs, noisy_sample_ys)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We used the following command to fit the regressor last time :\n",
    "\"from sklearn.neural_network import MLPRegressor\n",
    " mlp_model = MLPRegressor(max_iter=5000)\"\n",
    "\n",
    "By default, the MLP Regressor makes the following computational graph :\n",
    "- input gets multiplied by 100 parameters, and an additional parameter is added to each values, giving 100 outputs y\n",
    "- ReLU is applied to each of these outputs\n",
    "- Then all outputs are multiplied by a parameter (again 100 parameters) and all these values are summed and added to the result\n",
    "\n",
    "To make the two big multiplications, we will use one torch tensor of 100 parameters for each multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the parameters with small random initial values.\n",
    "# We need to mention that we want to compute a gradient\n",
    "# I provide you with the example for the first one, fill the others :\n",
    "w1 = torch.normal(mean=0., std=0.1, size=(100, 1), requires_grad=True)\n",
    "b1 = 0\n",
    "w2 = 0\n",
    "b2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then define the function, using torch.nn.functional.relu(x)\n",
    "def f(x, weight1=w1, bias1=b1, weight2=w2, bias2=b2):\n",
    "    out = torch.tensor(0)\n",
    "    return out\n",
    "\n",
    "\n",
    "# Just to be sure everything runs, we make an inference on one input\n",
    "sample_input = torch.ones(size=(1,))\n",
    "f(sample_input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will mostly use last class optimization procedure to train our network using Pytorch\n",
    "Fill out the learning loop, inspired by last time's class.\n",
    "Then plot the resulting model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also set up the data\n",
    "# Check that when doing inference on the data, we get an output tensor of size 80\n",
    "# Call us if it is not the case, there is something ~ subtle and not interesting\n",
    "torch_xs = torch.from_numpy(xs)[None, :]\n",
    "torch_ys = torch.from_numpy(noisy_sample_ys)\n",
    "f(torch_xs).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "optimizer can only optimize Tensors, but one of the params is int",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_6420/2694019991.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Now like last time, let us define an optimizer and give the parameters to it.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mn_iter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mopt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAdam\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mw1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mb1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mw2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mb2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/dpp/lib/python3.8/site-packages/torch/optim/adam.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001B[0m\n\u001B[1;32m     42\u001B[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001B[1;32m     43\u001B[0m                         weight_decay=weight_decay, amsgrad=amsgrad)\n\u001B[0;32m---> 44\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mAdam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdefaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__setstate__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/dpp/lib/python3.8/site-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, params, defaults)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mparam_group\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mparam_groups\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_param_group\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam_group\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__getstate__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/dpp/lib/python3.8/site-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36madd_param_group\u001B[0;34m(self, param_group)\u001B[0m\n\u001B[1;32m    208\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mparam\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mparam_group\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'params'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    209\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 210\u001B[0;31m                 raise TypeError(\"optimizer can only optimize Tensors, \"\n\u001B[0m\u001B[1;32m    211\u001B[0m                                 \"but one of the params is \" + torch.typename(param))\n\u001B[1;32m    212\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mparam\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_leaf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: optimizer can only optimize Tensors, but one of the params is int"
     ]
    }
   ],
   "source": [
    "# Now like last time, let us define an optimizer and give the parameters to it.\n",
    "n_iter = 100\n",
    "opt = torch.optim.Adam([w1, b1, w2, b2], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loop over the data, make the forward, backward, step and zero grad\n",
    "for i in range(n_iter):\n",
    "    pass\n",
    "    # if not i % 10:\n",
    "    #     print(i, loss.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch_lsp = torch.from_numpy(lsp)\n",
    "predicted_ys = f(torch_lsp).detach().numpy()\n",
    "\n",
    "plt.plot(lsp, true_ys, linestyle='dashed')\n",
    "plt.plot(lsp, predicted_ys)\n",
    "\n",
    "# Plot the samples\n",
    "plt.scatter(xs, noisy_sample_ys)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Congratulations, you have coded yourself a MLP model ! We have used the computation graph framework.\n",
    "Now let us make our code prettier (more Pytorch) and more efficient !\n",
    "\n",
    "First let us refactor the model in the proper way it should be coded, by using the torch.nn.Module class.\n",
    "You should add almost no new code, just reorganize the one above into a class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.nn import Module, Parameter\n",
    "\n",
    "\n",
    "class MyOwnMLP(Module):\n",
    "    def __init__(self):\n",
    "        super(MyOwnMLP, self).__init__()\n",
    "        self.w1 = Parameter(torch.normal(mean=0., std=0.1, size=(100, 1)))\n",
    "        # ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass (computation graph) like above\n",
    "        return out\n",
    "\n",
    "\n",
    "model = MyOwnMLP()\n",
    "out = model(torch_xs)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are good to also make the data iteration process look like Pytorch code !\n",
    "\n",
    "We need to define a Dataset object. Once we have this, we can use it to create a DataLoader object"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_x, data_y):\n",
    "        pass\n",
    "        # store the data\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "        # Return the number of points in your dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the x and y at a given position (index) in the data\n",
    "        x=0\n",
    "        y=0\n",
    "        return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loop and wait for each data point in PyTorch\n",
    "dataset = CustomDataset(data_x=xs, data_y=noisy_sample_ys)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=10, num_workers=6)\n",
    "start = time.time()\n",
    "for point in dataloader:\n",
    "    pass\n",
    "print('Done in pytorch : ', time.time() - start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last thing missing to make our pipeline truly Pytorch is to use a GPU.\n",
    "\n",
    "In Pytorch it is really easy, you just need to 'move' your tensors to a 'device'.\n",
    "You can test if a gpu is available and create the appropriate device with the following lines:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "torch_xs = torch_xs.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we finally have all the elements to make an actual Pytorch complete pipeline !\n",
    "\n",
    "Create a model, and try to put it on a device.\n",
    "Create an optimizer with your model's parameters\n",
    "Make your data into a dataloader\n",
    "\n",
    "Then use two nested for loops : one for 100 epochs, and in each epoch loop over the dataloader\n",
    "    Inside the loop, for every batch first put the data on the device\n",
    "    Then use the semantics of above :\n",
    "        - model(batch)\n",
    "        - loss computation and backward\n",
    "        - gradient step and zero_grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        # Don't forget to send to device, the rest is similar to what we had above\n",
    "        pass\n",
    "\n",
    "# To easily use the trained model we need to send it back to cpu at the end\n",
    "model = model.to('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We finally can plot the last model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch_lsp = torch.from_numpy(lsp)\n",
    "predicted_ys = model(torch_lsp).detach().numpy()\n",
    "\n",
    "plt.plot(lsp, true_ys, linestyle='dashed')\n",
    "plt.plot(lsp, predicted_ys)\n",
    "\n",
    "# Plot the samples\n",
    "plt.scatter(xs, noisy_sample_ys)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}