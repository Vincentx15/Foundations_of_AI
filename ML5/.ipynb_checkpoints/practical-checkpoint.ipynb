{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc77ac82",
   "metadata": {},
   "source": [
    "# Machine Learning 5: Real life example\n",
    "\n",
    "Our dataset is from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically **predict whether or not a patient has diabetes**, based on certain diagnostic measurements included in the dataset.\n",
    "\n",
    "The datasets consists of several medical predictor variables and one target variable, **Outcome**. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "\n",
    "Can you build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?\n",
    "\n",
    "The data is relatively clean, we won't discuss pre-processing in detail here, besides the very basics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398c1c4",
   "metadata": {},
   "source": [
    "First, let's **import the libraries** we will need. Then, we need to **read the csv file**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "diabetes = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837efdb1",
   "metadata": {},
   "source": [
    "Let's **print the columns and the few top values** from the dataset, to see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.____ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.____()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb6d7c",
   "metadata": {},
   "source": [
    "Let's take a look at the Outcome variable that we want to predict. **How many people from our dataset have diabetes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6dc990",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.groupby('Outcome').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857988a",
   "metadata": {},
   "source": [
    "Do we have **missing values** in any columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752aaaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.____().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92b1532",
   "metadata": {},
   "source": [
    "Let's look at the **distribution** of each feature to see if we find anything weird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.hist(figsize=(9, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92923ac5",
   "metadata": {},
   "source": [
    "From the histagram we can see `0` values for *Blood Pressure, BMI, Skin Fold Thikness, Insulin,* and *Blood Glucose*. Those values aren't realistic, and are probably in fact hidden **missing values**. \n",
    "\n",
    "For *Blood Pressure, BMI,* and *Glucose*, only a **few values** are missing. We can safely **drop** those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f696b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_mod = diabetes[(diabetes.BloodPressure != 0) & (diabetes.BMI != 0) & (diabetes.Glucose != 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da836a",
   "metadata": {},
   "source": [
    "It seems like there are a lot of `0` values in the *Insulin* column. Let's check how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes[diabetes.Insulin == 0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8216aec2",
   "metadata": {},
   "source": [
    "We will **lose a lot of information** if we remove all rows where Insulin value is zero. It seems like a valuable variable to drop it completely. Let's keep it for now and see how it goes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd74030",
   "metadata": {},
   "source": [
    "Now that the data is ready we can **train our model**. Let's try a model called Logistic Regression. \n",
    "\n",
    "First, we will create `X` variable with the **features**, and `y` variable with the **outcome**. We will need to split the data into **train and test sets**. There is a function `train_test_split` for this. Please google it to find scikit documentation with the example of usage. We will use **accuracy** to get the estimates. It's a good choice because our outcome variable is rather balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "X = diabetes_mod[feature_names]\n",
    "y = diabetes_mod.____\n",
    "\n",
    "X_train, X_test, y_train, y_test = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f65f3",
   "metadata": {},
   "source": [
    "Now the fun part! \n",
    "To get our predictions we need to:\n",
    "1. **Initialize** the model\n",
    "2. **Fit** the model (using the input feature vectors `X` and the outcome vector `y` of the **training set**)\n",
    "3. Use the trained model to **predict** outcome values from the **training set**, and then the **test set** (here, we only provide the input features `X`, the model will give us the predicted `y` values)\n",
    "4. **Compare** the values the model predicted with the actual outcome values. We will use the accuracy_score function. Please google how to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5589554",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(____, ____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27af7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394a8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.____(____)\n",
    "accuracy_score(____, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578abd56",
   "metadata": {},
   "source": [
    "## Congratulations on your first model! \n",
    "The accuracy on the test set is almost as good as the accuracy on the training set. That means that the model doesn't **overfit** to the training set.\n",
    "Let's try another model, that is famous for overfitting if not tuned well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.____(____, ____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e60a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = tree.____(____)\n",
    "accuracy_score(____, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = tree.____(____)\n",
    "accuracy_score(____, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe268b7",
   "metadata": {},
   "source": [
    "We can see that the model **fits the training data perfectly** (which is already suspicious), and performs much worse on the test set. One of the way to prevent overfitting is to force the model to be \"**simpler**\". For the Decision Tree algorithm, one of the indication of its complexity is its \"depth\". Let's try limiting it to `3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "tree.____(____, ____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefdf3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = tree.____(____)\n",
    "accuracy_score(____, ____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec506d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = tree.____(____)\n",
    "accuracy_score(____, ____)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df95232",
   "metadata": {},
   "source": [
    "Now we can see that the accuracy **decreased** for the training set, but **increased** for the test set. It means our model **generalizes** better, and will be able to predict unseen cases. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
