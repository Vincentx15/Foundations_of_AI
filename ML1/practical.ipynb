{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Practical Session 1 - High level view of ML\n",
    "\n",
    "This is the first practical session. In this session we will see how to setup a machine learning problem.\n",
    "We will first generate a toy problem to have control over our data and plot it.\n",
    "\n",
    "Then we will see how to fit an easy model. We will then compute its mean error, plot its prediction and see what happens when changing the data\n",
    "\n",
    "Finally we will use more powerful model and redo this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## A dummy regression task\n",
    "\n",
    "### Generating data\n",
    "Let us assume that our data is just some samples 'x' and the underlying hidden relationship is a simple function of x :\n",
    "$y(x) = 1.3 x^3 - 3x^2 + 3.6*x + 6.9$\n",
    "We want to take random points in a certain range uniformly, which can be done with np.random.uniform.\n",
    "\n",
    "Get 100 random points between -1 and 3. Compute their label. Also create a noisy version of these : you can do so by adding small noise (take the default settings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(20)\n",
    "\n",
    "low, high = -1, 3\n",
    "n_points = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plotting our data\n",
    "The most used plotting tool for Python is matplotlib.pyplot, also often complemented by seaborn.\n",
    "You should use the functions plot (draw a line) and scatter (draw points) for most of this class.\n",
    "\n",
    "To plot a function, the most common way is to generate evenly spaced points using np.linspace. Then you can transform them with your function and use plot to see your function. Plot the base function in the interval [-1, 3]\n",
    "\n",
    "Also plot the data you generated using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fitting a simple model : Linear Regression\n",
    "\n",
    "Use scikit learn LinearRegression object to fit a model on your noisy samples.\n",
    "Once fitted, plot the resulting model along with the samples. Does this look good to you ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_26025/2089524992.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mlinear_model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mxs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mxs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlinear_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLinearRegression\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnoisy_sample_ys\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mpredicted_lsp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlsp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'xs' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "xs = xs[:, None]\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(xs, noisy_sample_ys)\n",
    "predicted_lsp = model.predict(lsp)\n",
    "plt.scatter(xs, noisy_sample_ys)\n",
    "plt.plot(lsp, predicted_lsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative assessment of the quality\n",
    "\n",
    "We want to know how good/bad is our model. To do so we will use numpy to compute the mean absolute difference over our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is hard to interpret per se. However we can see what would happen if the noise around the model would be greatly augmented. Generate a new set of labels with a noise sampled with a scale parameter of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Towards a more complicated model : a first neural network\n",
    "\n",
    "Let us now go back to our original data. \n",
    "\n",
    "We want to replace the previous simple linear model, with a very simple neural network. We don't have to code it, there exist an easy one already implemented in scikit learn : MLPRegressor(max_iter=5000). \n",
    "Redo the same plot as before and see how the fit now looks better.\n",
    "\n",
    "You can try changing the number of iterations or playing a bit with the parameters and see the impact on the fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean absolute difference as before. What can you say about the metrics ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A dummy classification task now\n",
    "\n",
    "Let us redo most steps but in classification setting : The new function we want to learn is the arbitrary following one : \n",
    "$y(x) = round(\\frac{1}{1+exp(-(1.3 x^3 - 5 x^2 + 3.6^x + 1.6)}))$\n",
    "It is already implemented and returns zero, one or two.\n",
    "\n",
    "Redo the previous steps of generating and plotting the data as well as the underlying relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_function():\n",
    "    f = lambda x: np.round(2/(1+np.exp(-(1.3 * x ** 3 - 5 * x ** 2 + 3.6 * x + 1.6))))\n",
    "    return f\n",
    "bfunc = base_function()\n",
    "\n",
    "low, high = -1, 3\n",
    "n_points = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit a small neural network using scikit learn again, using MLPClassifier(max_iter=5000). Can this model properly learn the underlying function ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_model = MLPClassifier(max_iter=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the absolute difference does not really make sense as a metric. We can count the error rate. This amounts to to the ratio of the predictions where the predicted value and the true one differ. What is the error rate of your model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}